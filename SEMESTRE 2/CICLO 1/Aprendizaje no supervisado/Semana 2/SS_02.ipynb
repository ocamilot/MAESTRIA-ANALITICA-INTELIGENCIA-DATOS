{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"figs/ans_banner_1920x200.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sesión Sincrónica Semana 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este cuaderno es cubrir las dudas, preguntas, y dificultades que detectamos en los trabajos entregados en la Semana 1 y hacer una introducción a la temática tratada en la semana 2.\n",
    "\n",
    "\n",
    "**NO** es necesario editar el archivo o hacer una entrega. Los ejemplos contienen celdas con código ejecutable (`en gris`), que podrá modificar libremente. Esta puede ser una buena forma de aprender nuevas funcionalidades del *cuaderno*, o experimentar variaciones en los códigos de ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los datos suelen venir con información, redundancia y ruido. \n",
    "\n",
    "\n",
    "- Nuestro objetivo siempre es extraer la máxima información posible de los datos mientras reducimos el ruido e ignoramos la información redundante. \n",
    "\n",
    "\n",
    "- Al hacer esto esamos reduciendo la dimensión y es uno de los objetivo de PCA\n",
    "\n",
    "\n",
    "- PCA nos permite resumir este conjunto de datos en un número pequeño de variables representativas.\n",
    "\n",
    "\n",
    "- Para ello busca transformar los datos de forma tal que tengamos la máxima información posible. \n",
    "\n",
    "\n",
    "- Como se mide información? En PCA y en otrós metodos estadísticos utilizamos la varianza. \n",
    "\n",
    "\n",
    "- Si algo varía más entonces tiene más información.\n",
    "\n",
    "\n",
    "- PCA identifica entonces eje que representa la mayor cantidad de variación en los datos.\n",
    "\n",
    "- Como lo hace? A través de combinaciones lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importancia de Estandarizar: Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos las librerías a utilizar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargamos y visualizamos la primeras observaciones de los datos\n",
    "X2 = pd.read_csv('data/simulated_data1.csv')\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pca import pca\n",
    "\n",
    "model = pca()\n",
    "\n",
    "results = model.fit_transform(X2, verbose=False)\n",
    "\n",
    "# Plot explained variance\n",
    "fig, ax = model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ver los pesos o loadings\n",
    "loadings_pca=model.results['loadings'].transpose()\n",
    "loadings_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA estandarizado\n",
    "model_norm = pca( normalize=True, verbose=False)\n",
    "\n",
    "# Fit transform\n",
    "results_norm = model_norm.fit_transform(X2)\n",
    "\n",
    "# Plot explained variance\n",
    "fig, ax = model_norm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X2.plot.scatter(x=\"X1\", y=\"X2\", c =\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_std = (X2 - X2.mean())/X2.std()\n",
    "\n",
    "X2_std.plot.scatter(x=\"X1\", y=\"X2\", c =\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## PCA como filtro de ruido: Dígitos escritos a mano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El PCA también puede usarse como un enfoque de filtrado para datos con ruido.\n",
    "\n",
    "- La idea es, cualquier componente con una varianza mucho mayor que el efecto del ruido debería verse relativamente poco afectado por el ruido. Por lo tanto, si reconstruyes los datos utilizando solo el subconjunto más grande de componentes principales, deberías estar conservando preferentemente la señal y eliminando el ruido.\n",
    "\n",
    "\n",
    "- Veamos cómo se ve esto con los [datos de dígitos](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) disponibles en los datos de [scikit-learn](https://scikit-learn.org/stable/). \n",
    "\n",
    "\n",
    "Comenzamos cargando los datos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "digits = load_digits()\n",
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vamos a graficar algunos de los datos de entrada sin ruido, teniendo en cuenta que son imágenes de 8×8 píxeles. :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(data):\n",
    "    fig, axes = plt.subplots(4, 10, figsize=(10, 4),\n",
    "                             subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                             gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(data[i].reshape(8, 8),\n",
    "                  cmap='binary', interpolation='nearest',\n",
    "                  clim=(0, 16))\n",
    "plot_digits(digits.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, agreguemos algo de ruido aleatorio para crear un conjunto de datos ruidoso (aumentamos la varianza) y volvamos a graficarlo:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# agregamos \"varianza\"\n",
    "noisy = np.random.normal(digits.data, 4)\n",
    "plot_digits(noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista, es evidente que las imágenes están ruidosas y contienen píxeles que no aportan información. \n",
    "\n",
    "Vamos a entrenar un PCA en los datos ruidosos, solicitando que la proyección preserve el 50% de la varianza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.50).fit(noisy)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí, el 50% de la varianza equivale a 12 componentes principales. Ahora, calculamos estos componentes y luego utilizamos la inversa de la transformación para reconstruir los dígitos filtrados:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pca.transform(noisy)\n",
    "filtered = pca.inverse_transform(components)\n",
    "plot_digits(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA tiene la capacidad de conservar la señal importante y filtrar el ruido. Esto es especialmente útil cuando trabajamos con datos que pueden estar contaminados con ruido aleatorio.\n",
    "  \n",
    "- Esta propiedad convierte a PCA en una herramienta poderosa para seleccionar las características más relevantes de los datos.\n",
    "\n",
    "- En lugar de entrenar un clasificador con datos de alta dimensionalidad (lo que puede ser costoso y propenso a errores), puedes entrenarlo usando una representación de menor dimensión generada por PCA.\n",
    "\n",
    "- Al reducir la dimensionalidad, PCA no solo hace que el proceso de entrenamiento sea más eficiente, sino que también ayuda a eliminar el ruido aleatorio en las entradas, mejorando la precisión del clasificador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA para visualización\n",
    "\n",
    "- Para obtener una mejor intuición sobre las relaciones entre estos puntos, podemos usar PCA para proyectarlos a un número de dimensiones más manejable, digamos dos\n",
    "\n",
    "- Los datos consisten en imágenes de 8×8 píxeles, lo que significa que son de 64 dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2)  # projectar de 64 a 2 dimensiones\n",
    "projected = pca.fit_transform(digits.data)\n",
    "print(digits.data.shape)\n",
    "print(projected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos graficar los dos primeros componentes principales de cada punto para aprender más sobre los datos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))  # Ajusta el tamaño de la figura, en este caso, 10x8 pulgadas\n",
    "\n",
    "plt.scatter(projected[:, 0], projected[:, 1],\n",
    "            c=digits.target, edgecolor='none', alpha=0.5,\n",
    "            cmap=plt.cm.get_cmap('nipy_spectral', 10))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();\n",
    "\n",
    "plt.show()  # Muestra la figura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Esta proyección nos permite visualizar cómo se distribuyen los dígitos en estas dos nuevas dimensiones, que son las que capturan la mayor parte de la información importante.\n",
    "\n",
    "- Esencialmente, hemos encontrado una manera de representar la información más importante de los datos (originalmente en 64 dimensiones) en solo 2 dimensiones. Esta simplificación nos permite ver patrones y diferencias entre los dígitos de manera más clara, sin necesidad de saber de antemano cuáles son los dígitos.\n",
    "\n",
    "- Lo hicimos de manera no supervisada, lo que significa que encontramos estas direcciones importantes sin usar ninguna información sobre qué dígito es cada punto (es decir, sin usar las etiquetas de los datos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué significan los componentes?\n",
    "\n",
    "Cuando reducimos la dimensión de los datos con PCA, los datos originales (en este caso, imágenes de dígitos) se representan en un espacio más pequeño. Pero, ¿qué significan realmente estas nuevas dimensiones?\n",
    "\n",
    "Imagina que cada imagen está formada por 64 valores, uno para cada píxel. Estos valores se organizan en un vector llamado \\( x \\), que luce algo así:\n",
    "\n",
    "$$\n",
    "x = [x_1, x_2, x_3, \\cdots, x_{64}]\n",
    "$$\n",
    "\n",
    "#### Construcción de la imagen\n",
    "\n",
    "Podemos pensar en la construcción de la imagen como una combinación de estos píxeles:\n",
    "\n",
    "- Multiplicamos cada valor del vector \\( x \\) por el píxel correspondiente en la imagen.\n",
    "- Luego, sumamos todos esos productos para reconstruir la imagen completa.\n",
    "\n",
    "Esto se ve así:\n",
    "\n",
    "$$\n",
    "\\text{imagen}(x) = x_1 \\cdot \\text{(píxel 1)} + x_2 \\cdot \\text{(píxel 2)} + x_3 \\cdot \\text{(píxel 3)} + \\cdots + x_{64} \\cdot \\text{(píxel 64)}\n",
    "$$\n",
    "\n",
    "#### Reducción de Dimensión\n",
    "\n",
    "Ahora, si quisiéramos reducir la dimensión de estos datos, una forma de hacerlo sería poner a cero la mayoría de estos valores y dejar solo unos pocos.\n",
    "\n",
    "Por ejemplo, si solo usamos los primeros 8 valores (correspondientes a los primeros 8 píxeles), obtendríamos una versión simplificada de la imagen en un espacio de solo 8 dimensiones. Pero, esta versión no representaría muy bien la imagen completa, porque habríamos descartado casi el 90% de los píxeles.\n",
    "\n",
    "### ¿Por qué importa?\n",
    "\n",
    "La reducción de dimensión con PCA no solo elige algunos píxeles al azar; en lugar de eso, encuentra las combinaciones de píxeles que mejor representan la variación en las imágenes, asegurándose de que la información más importante se conserve incluso en un espacio más pequeño.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import load_digits\n",
    "import seaborn as sns\n",
    "\n",
    "digits = load_digits()\n",
    "sns.set_style('white')\n",
    "\n",
    "\n",
    "\n",
    "def plot_pca_components(x, coefficients=None, mean=0, components=None,\n",
    "                        imshape=(8, 8), n_components=8, fontsize=12,\n",
    "                        show_mean=True):\n",
    "    if coefficients is None:\n",
    "        coefficients = x\n",
    "        \n",
    "    if components is None:\n",
    "        components = np.eye(len(coefficients), len(x))\n",
    "        \n",
    "    mean = np.zeros_like(x) + mean\n",
    "        \n",
    "\n",
    "    fig = plt.figure(figsize=(1.2 * (5 + n_components), 1.2 * 2))\n",
    "    g = plt.GridSpec(2, 4 + bool(show_mean) + n_components, hspace=0.3)\n",
    "\n",
    "    def show(i, j, x, title=None):\n",
    "        ax = fig.add_subplot(g[i, j], xticks=[], yticks=[])\n",
    "        ax.imshow(x.reshape(imshape), interpolation='nearest')\n",
    "        if title:\n",
    "            ax.set_title(title, fontsize=fontsize)\n",
    "\n",
    "    show(slice(2), slice(2), x, \"True\")\n",
    "    \n",
    "    approx = mean.copy()\n",
    "    \n",
    "    counter = 2\n",
    "    if show_mean:\n",
    "        show(0, 2, np.zeros_like(x) + mean, r'$\\mu$')\n",
    "        show(1, 2, approx, r'$1 \\cdot \\mu$')\n",
    "        counter += 1\n",
    "\n",
    "    for i in range(n_components):\n",
    "        approx = approx + coefficients[i] * components[i]\n",
    "        show(0, i + counter, components[i], r'$c_{0}$'.format(i + 1))\n",
    "        show(1, i + counter, approx,\n",
    "             r\"${0:.2f} \\cdot c_{1}$\".format(coefficients[i], i + 1))\n",
    "        if show_mean or i > 0:\n",
    "            plt.gca().text(0, 1.05, '$+$', ha='right', va='bottom',\n",
    "                           transform=plt.gca().transAxes, fontsize=fontsize)\n",
    "\n",
    "    show(slice(2), slice(-2, None), approx, \"Approx\")\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_pca_components(digits.data[10],\n",
    "                          show_mean=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Fila Superior**: Muestra cómo contribuyen los píxeles individuales a la imagen final.\n",
    "- **Fila Inferior**: Muestra cómo se acumula la contribución de esos píxeles a medida que se agregan para construir la imagen.\n",
    "\n",
    "- Si usamos solo 8 píxeles para reconstruir la imagen, solo podremos capturar una pequeña parte de la imagen original (que tiene 64 píxeles).\n",
    "- Si seguimos sumando los píxeles restantes, al final recuperaremos la imagen completa.\n",
    "\n",
    "### Bases Alternativas y PCA\n",
    "\n",
    "- **Representación Píxel a Píxel**: No es la única forma de construir la imagen. También podemos usar otras \"funciones base\", que son combinaciones predefinidas de píxeles.\n",
    "- **Ejemplo**: La imagen podría construirse sumando una \"imagen base\" (media) más combinaciones de funciones base, así:\n",
    "\n",
    "  $$\n",
    "  \\text{imagen}(x) = \\text{media} + x_1 \\cdot \\text{(base 1)} + x_2 \\cdot \\text{(base 2)} + x_3 \\cdot \\text{(base 3)} + \\cdots\n",
    "  $$\n",
    "\n",
    "#### ¿Qué Hace PCA?\n",
    "\n",
    "- **Selección de Funciones Base**: PCA es como un proceso que elige las mejores funciones base para que, al sumar solo las primeras pocas, se pueda reconstruir la mayor parte de la información de los datos.\n",
    "- **Componentes Principales**: Son los coeficientes que multiplican cada función base en la serie. Estas funciones son las que capturan las características más importantes de los datos.\n",
    "\n",
    "- **Imagen Reconstruida**: Si reconstruimos un dígito usando la media más las primeras ocho funciones base de PCA, obtendremos una representación que ya captura gran parte de la imagen original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=8)\n",
    "Xproj = pca.fit_transform(digits.data)\n",
    "sns.set_style('white')\n",
    "fig = plot_pca_components(digits.data[10], Xproj[10],\n",
    "                          pca.mean_, pca.components_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia de la base de píxeles, la base de PCA nos permite recuperar las características sobresalientes de la imagen con solo una media más ocho componentes.\n",
    "\n",
    "Este es el sentido en el que PCA proporciona una representación de baja dimensionalidad de los datos: descubre un conjunto de funciones base que son más eficientes que la base de píxeles nativa de los datos de entrada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descomposición en Valores Singulares. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En la segunda semana  nos enfocamos en otra forma de análisis matricial que conduce a representaciones de baja dimensión de matrices altamente dimensionales.\n",
    "\n",
    "Este enfoque llamado descomposición en valores singulares (SVD), permite una representación exacta de cualquier matriz, facilitando también la eliminación de las partes menos importantes de esa representación. \n",
    "\n",
    "Por supuesto, cuantas menos dimensiones elijamos, menos precisa será la aproximación.\n",
    "\n",
    "\n",
    "## Usos de la SVD\n",
    "\n",
    "- Reducción de Dimensiones: Puede usarse para reducir la dimensionalidad de los datos, manteniendo la información más importante.\n",
    "- Filtrado de Ruido: Ayuda a eliminar el ruido en los datos al conservar sólo los componentes principales.\n",
    "- Recomendación: En sistemas de recomendación, SVD puede usarse para predecir los elementos que un usuario podría preferir.\n",
    "\n",
    "## Diferencias entre SVD y PCA\n",
    "\n",
    "   - Objetivo:\n",
    "     - SVD descompone una matriz en tres matrices para revelar sus propiedades matemáticas.\n",
    "     - PCA busca una proyección que capture la mayor varianza en los datos.\n",
    "\n",
    "   - Metodología:\n",
    "     -  SVD se aplica directamente a la matriz de datos.\n",
    "     -  PCA se aplica a la matriz de covarianza de los datos, y a menudo se utiliza SVD en el proceso de calcular PCA.\n",
    "\n",
    "   - Aplicación:\n",
    "     - SVD tiene una variedad de aplicaciones en matemáticas, estadísticas y ciencias de la computación.\n",
    "     - PCA se utiliza principalmente para la visualización y reducción de dimensiones en análisis de datos.\n",
    "\n",
    "En resumen, aunque SVD y PCA pueden parecer similares y PCA incluso puede implementarse utilizando SVD, tienen objetivos y aplicaciones diferentes. SVD es una técnica más general y fundamental, mientras que PCA es una aplicación específica de análisis de datos que a menudo utiliza SVD en su cálculo.\n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "Iniciamos este cuaderno con una introducción general y las definiciones matemáticas necesarias. Luego exploramos la idea de reconocimiento facial aplicados a los rostros de Olivetti.\n",
    "\n",
    "\n",
    "## Definiciones\n",
    "\n",
    "- Supongamos que $ X $ es una matriz $ n \\times k $  con rango $ r $. Donde necesariamente, $ r \\leq \\min(n,k) $. (Recordemos que el [rango de una matriz](https://es.wikipedia.org/wiki/Rango_(%C3%A1lgebra_lineal)) es el número máximo de columnas (filas respectivamente) que son linealmente independientes.)\n",
    "\n",
    "\n",
    "- Podemos pensar esta matriz $X$ como los datos\n",
    "\n",
    "    - Cada fila es una observación\n",
    "    - Cada columna es una variable aleatoria que describe un atributo.\n",
    "\n",
    "\n",
    "### Singular Value Decomposition\n",
    "\n",
    "La **descomposición en valores singulares** de una matriz $X$, $ n \\times k $ matrix $ X $ de rango $ r \\leq \\min(n,k) $ es\n",
    "\n",
    "$$\n",
    "X  = U \\Sigma V^T\n",
    "$$\n",
    "\n",
    "donde\n",
    "\n",
    "- $ U $ es una matriz $ n \\times n $ cuyas columnas son eigen vectores de  $ X^T X $  \n",
    "\n",
    "- $ V $ es una matriz $ k \\times k $ cuyas columnas son eigen vectores de  $ X X^T $  \n",
    "\n",
    "- $ \\Sigma $ es una matriz $ n \\times k $ en cuyos $ r $ lugares de su diagonal principal hay números positivos  $ \\sigma_1, \\sigma_2, \\ldots, \\sigma_r $ llamados **valores singulares**; y las entradas restantes de  $ \\Sigma $ son todos ceros.\n",
    "\n",
    "- Los $ r $ valores singulares son la raiz cuadrada de los eigen values de la matriz $ X X^T $ de dimension $ n \\times n $ y de la matriz $ k \\times k $ matrix $, X^T X $  \n",
    "\n",
    "\n",
    "\n",
    "![](figs/svd_a3.png)\n",
    "\n",
    "\n",
    "\n",
    "#### SVD Completa vs. Delgada (Reducida)\n",
    "\n",
    "En la SVD completa, las dimensiones de $U$, $\\Sigma$, y $V$ son $n \\times n$, $n \\times k$, y $k \\times k$ respectivamente:\n",
    "\n",
    "\\begin{align}\n",
    "\\underset{n\\times k}{\\underbrace{X}}=\\underset{n\\times n}{\\underbrace{U}}\\underset{n\\times k}{\\underbrace{\\Sigma}}\\underset{k\\times k}{\\underbrace{V^T}}\n",
    "\\end{align}\n",
    "\n",
    "Existe también una versión delgada (o reducida) de la SVD, que evita calcular las columnas adicionales de $U$ que se multiplican por ceros en $\\Sigma$. En esta descomposición, denotada como $\\hat{U}\\hat{\\Sigma}\\hat{V}^T$:\n",
    "\n",
    "\\begin{align}\n",
    "\\underset{n\\times k}{\\underbrace{X}}=\\underset{n\\times r}{\\underbrace{\\hat{U}}}\\underset{r\\times r}{\\underbrace{\\hat{\\Sigma}}}\\underset{r\\times k}{\\underbrace{\\hat{V}^T}}\n",
    "\\end{align}\n",
    "\n",
    "Aquí, $U$, $\\Sigma$, y $V$ se reducen a matrices de dimensiones $n \\times r$, $r \\times r$, y $k \\times r$ respectivamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD y Reducción de Dimensión\n",
    "\n",
    "Cuando trabajamos con datos de alta dimensionalidad, como grandes matrices que representan, por ejemplo, imágenes, textos o series temporales, es común que algunas de esas dimensiones (columnas) no contribuyan significativamente a la estructura de los datos. Aquí es donde entra en juego la SVD para la reducción de dimensión.\n",
    "\n",
    "##### **Paso a Paso: Reducción de Dimensión con SVD**\n",
    "\n",
    "1. **Descomposición**:\n",
    "   - Comenzamos descomponiendo la matriz de datos $X$ en las tres matrices $U$, $\\Sigma$, y $V^T$ mediante SVD:\n",
    "     $$\n",
    "     X = U \\Sigma V^T\n",
    "     $$\n",
    "\n",
    "2. **Ordenación de Importancia**:\n",
    "   - Los valores singulares en $\\Sigma$ están ordenados de mayor a menor. Los primeros valores singulares corresponden a las direcciones (o \"conceptos\") más importantes en la matriz de datos. Los valores singulares pequeños indican direcciones que contribuyen menos a la estructura general de los datos.\n",
    "\n",
    "3. **Selección de Componentes**:\n",
    "   - Para reducir la dimensionalidad, podemos seleccionar solo los primeros $r$ valores singulares más grandes (y sus correspondientes vectores singulares en $U$ y $V^T$), y descartar el resto. Esto da lugar a una matriz $\\Sigma_r$, una versión truncada de $\\Sigma$, y matrices reducidas $ U_r$ y $V_r^T$.\n",
    "\n",
    "4. **Aproximación**:\n",
    "   - Con las matrices reducidas $U_r$, $\\Sigma_r$, y $V_r^T$, obtenemos una nueva matriz $X_r$ que es una aproximación de $X$ pero con menos dimensiones:\n",
    "     $$\n",
    "     X_r = U_r \\Sigma_r V_r^T\n",
    "     $$\n",
    "   - Esta matriz $X_r$ captura la mayor parte de la variabilidad en los datos originales $X$ pero con un número mucho menor de dimensiones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Relación entre SVD Delgada y SVD Truncada**\n",
    "\n",
    "Ambas técnicas están diseñadas para reducir la dimensión de los datos originales, pero lo hacen en diferentes grados:\n",
    "\n",
    "1. **SVD Delgada**:\n",
    "   - Mantiene todos los componentes significativos (hasta el rango $r$) y proporciona una representación compacta que aún preserva toda la información relevante de los datos.\n",
    "   - Es útil cuando queremos una representación más económica sin perder ninguna dimensión significativa.\n",
    "\n",
    "2. **SVD Truncada**:\n",
    "   - Va un paso más allá al eliminar incluso algunos componentes significativos si se considera que no son necesarios para la aplicación específica. Se enfoca en conservar solo los $k$ valores singulares más grandes, donde $k$ es un número que decidimos en función de la cantidad de información que queremos preservar.\n",
    "   - Es extremadamente útil en situaciones donde se necesita una representación aún más compacta, como en la compresión de datos o en la construcción de modelos de aprendizaje automático que deben ser rápidos y eficientes.\n",
    "\n",
    "\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Supongamos que tienes un conjunto de imágenes de rostros de 100x100 píxeles (10,000 dimensiones). Aplicando:\n",
    "\n",
    "- **SVD Delgada**: Si el rango $r$ de la matriz de imágenes es 100, la SVD delgada mantendría 100 componentes, proporcionando una reconstrucción fiel pero con una reducción en el almacenamiento (de 10,000 dimensiones a 100 dimensiones).\n",
    "\n",
    "- **SVD Truncada**: Si decides truncar la SVD a los primeros 50 valores singulares, reducirías aún más las dimensiones a 50, pero perderías algunas características más sutiles de la imagen, aunque podrías comprimirla significativamente ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Rostros de Olivetti.\n",
    "\n",
    "Aplicar SVD a un conjunto de imágenes permite identificar los patrones principales en las caras (como la forma general de la cara, posición de los ojos, etc.), y reducir la dimensión de la imagen original. \n",
    "\n",
    "Al utilizar solo los componentes principales, se puede lograr una representación compacta que sigue siendo altamente efectiva para tareas como la clasificación o identificación de rostros, mientras se ignoran detalles irrelevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Cargar datos\n",
    "oliveti_dataset = fetch_olivetti_faces(data_home=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oliveti_dataset.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oliveti_dataset.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, h, w = oliveti_dataset.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplasto los datos para poder trabajar \"mas intuitivamente\" con las matrices\n",
    "X = oliveti_dataset.data\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "y = oliveti_dataset.target\n",
    "y = pd.DataFrame(y, columns=['pid']) # pid is person_id\n",
    "\n",
    "df = y.join(X)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a figure to plot\n",
    "img1=X.iloc[300].to_numpy().reshape(h,w)\n",
    "plt.imshow(img1, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_tplot=df.drop(columns=['pid'])\n",
    "n_row=1\n",
    "n_col=10\n",
    "\n",
    "plt.figure(figsize=(1.5 * n_col, 2.2 * n_row))\n",
    "plt.subplots_adjust(0.6, 0.5, 1.5, 1.5)\n",
    "for i in range(n_row * n_col):\n",
    "    plt.subplot(n_row, n_col, i + 1)\n",
    "    plt.imshow(faces_tplot.iloc[i].to_numpy().reshape((h, w)), cmap=plt.cm.gray)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Rostro promedio. \n",
    "\n",
    " Encuentre el rostro promedio, para ello calcule la media por columnas o la media por píxel y grafíquelo.\n",
    "\n",
    "- El objetivo es  encontrar las características que hacen que los individuos sean diferentes a los demás. \n",
    "\n",
    "-  La razón por la que esto es necesario es porque queremos crear un sistema que pueda representar cualquier rostro. \n",
    "\n",
    "- Por lo tanto, calculamos los elementos que todas las caras tienen en común (la media). \n",
    "\n",
    "- Si extraemos esta media de las imagen, se aprecian las características que distinguen cada fotografía del resto del conjunto. Maximizamos la varianza!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilice este espacio para escribir el código.\n",
    "Xmean = df.drop(columns=[ 'pid']).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the average face \n",
    "plt.imshow(Xmean.to_numpy().reshape((h, w)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Reste el rostro promedio.\n",
    "\n",
    "A cada una de las imágenes substraigale el rostro promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Demean=df.drop(columns=['pid'])-Xmean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some examples\n",
    "n_row=8\n",
    "n_col=5\n",
    "\n",
    "plt.figure(figsize=(1.5 * n_col, 2.2 * n_row))\n",
    "plt.subplots_adjust(0.6, 0.5, 1.5, 1.5)\n",
    "for i in range(n_row * n_col):\n",
    "    plt.subplot(n_row, n_col, i + 1)\n",
    "    plt.imshow(Demean.iloc[i].to_numpy().reshape((h, w)), cmap=plt.cm.gray)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Descomposición en Valores Singulares \n",
    "\n",
    "Aplique la Descomposición en Valores Singulares a estas nuevas imágenes y retenga solo $K$ eigen vectores que mejor representen las imágenes. Justifique su elección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import svd #pueden explorar con sklearn\n",
    "U,S,Vt = svd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe cuan rapidamente caen los SVD\n",
    "idx = range(len(S))\n",
    "func = [S[0]/((i+1) ** 2) for i in idx ]\n",
    "\n",
    "plt.figure(figsize = (8, 6))\n",
    "plt.plot(idx, func, color = 'r')\n",
    "plt.scatter(idx, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg =50\n",
    "idx = range(0,rg)\n",
    "var_explained = np.round(S**2/np.sum(S**2), decimals=6)\n",
    "\n",
    "cumsum=var_explained[0:rg].cumsum()\n",
    "\n",
    "plt.figure(figsize = (8, 6))\n",
    "plt.plot(idx,cumsum , color = 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(var_explained[0:rg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,k=X .shape\n",
    "\n",
    "S2= np.resize(S,[n,1])*np.eye(n,k) #ponemos los valores singulares en una matriz diagonal\n",
    "\n",
    "l = 10\n",
    "\n",
    "reconstructed=np.dot(U[:,0:l],np.dot(S2[0:l,0:l],Vt[0:l,:]))\n",
    "reconstructed = pd.DataFrame(reconstructed)\n",
    "reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imag10_index=df.loc[df['pid'] == 10].index\n",
    "imag10=reconstructed.iloc[imag10_index]\n",
    "\n",
    "imag10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos\n",
    "n_row=2\n",
    "n_col=5\n",
    "\n",
    "plt.figure(figsize=(1.5 * n_col, 2.2 * n_row))\n",
    "plt.subplots_adjust(0.6, 0.5, 1.5, 1.5)\n",
    "for i in range(n_row * n_col):\n",
    "    plt.subplot(n_row, n_col, i + 1)\n",
    "    plt.imshow(imag10.iloc[i].to_numpy().reshape((h, w)), cmap=plt.cm.gray)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Información de Sesión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import session_info\n",
    "\n",
    "session_info.show(html=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
